{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2221d9ce0419513808069487a0bbb7a240bfa6db"
   },
   "source": [
    "# Data enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32af863b96dea6b55e2edb2ef9efd3b7700eeb47"
   },
   "source": [
    "### <u>Content:<u>\n",
    "\n",
    "[1) Load data ](#load_data) \n",
    "\n",
    "[2) Wochentag\n",
    "    \n",
    "[3) Ferien Anzahl Personen\n",
    "    \n",
    "[4) Koordinaten\n",
    "\n",
    "[5 Wetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "3fb7e3274cdb7252c5434d45e35b5db673d83a1f"
   },
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from scipy.spatial.distance import cdist\n",
    "rcParams['figure.figsize']=10,8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dba61c61e778a17f4fc311b7e207268a0068c262"
   },
   "source": [
    "#### 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "_uuid": "f3336d998053e4d1e6bc2760a7b5ed3a65b525be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reservations: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>res_id</th>\n",
       "      <th>res_dt</th>\n",
       "      <th>date</th>\n",
       "      <th>train_nr</th>\n",
       "      <th>line</th>\n",
       "      <th>reserved</th>\n",
       "      <th>capacity</th>\n",
       "      <th>bp_from</th>\n",
       "      <th>bp_to</th>\n",
       "      <th>dep_ist</th>\n",
       "      <th>dep_soll</th>\n",
       "      <th>arr_ist</th>\n",
       "      <th>arr_soll</th>\n",
       "      <th>res_delta_ist</th>\n",
       "      <th>res_delta_soll</th>\n",
       "      <th>res_delta_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>226735</th>\n",
       "      <td>226735</td>\n",
       "      <td>246187</td>\n",
       "      <td>31/10/2021 17:16</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>1635</td>\n",
       "      <td>IC 51</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>BI</td>\n",
       "      <td>DMT</td>\n",
       "      <td>31/10/2021 19:49</td>\n",
       "      <td>31/10/2021 19:49</td>\n",
       "      <td>31/10/2021 20:17</td>\n",
       "      <td>31/10/2021 20:18</td>\n",
       "      <td>9216.0</td>\n",
       "      <td>9210</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  res_id            res_dt       date  train_nr   line  \\\n",
       "226735      226735  246187  31/10/2021 17:16 2021-10-31      1635  IC 51   \n",
       "\n",
       "        reserved  capacity bp_from bp_to           dep_ist          dep_soll  \\\n",
       "226735         1       6.0      BI   DMT  31/10/2021 19:49  31/10/2021 19:49   \n",
       "\n",
       "                 arr_ist          arr_soll  res_delta_ist  res_delta_soll  \\\n",
       "226735  31/10/2021 20:17  31/10/2021 20:18         9216.0            9210   \n",
       "\n",
       "        res_delta_valid  \n",
       "226735             True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schulferien: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canton</th>\n",
       "      <th>population</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>national</td>\n",
       "      <td>7917100</td>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>2022-12-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       canton  population      start        end\n",
       "161  national     7917100 2022-12-25 2022-12-26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabea\\miniconda3\\envs\\geo_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (15) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abk_bahnhof</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47113</th>\n",
       "      <td>BRIA</td>\n",
       "      <td>47.260083</td>\n",
       "      <td>7.942674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      abk_bahnhof        lat       lon\n",
       "47113        BRIA  47.260083  7.942674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>validdate</th>\n",
       "      <th>leisure_biking:idx</th>\n",
       "      <th>snow_depth:cm</th>\n",
       "      <th>t_2m:C</th>\n",
       "      <th>precip_24h:mm</th>\n",
       "      <th>weather_symbol_1h:idx</th>\n",
       "      <th>effective_cloud_cover:octas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>station_id</td>\n",
       "      <td>validdate</td>\n",
       "      <td>leisure_biking:idx</td>\n",
       "      <td>snow_depth:cm</td>\n",
       "      <td>t_2m:C</td>\n",
       "      <td>precip_24h:mm</td>\n",
       "      <td>weather_symbol_1h:idx</td>\n",
       "      <td>effective_cloud_cover:octas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id  validdate  leisure_biking:idx  snow_depth:cm  t_2m:C  \\\n",
       "4745  station_id  validdate  leisure_biking:idx  snow_depth:cm  t_2m:C   \n",
       "\n",
       "      precip_24h:mm  weather_symbol_1h:idx  effective_cloud_cover:octas  \n",
       "4745  precip_24h:mm  weather_symbol_1h:idx  effective_cloud_cover:octas  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read the reservation data \n",
    "df = pd.read_csv('reservation_data_2019-2021_incl_capacity/reservation_data_2019-2021_incl_capacity.csv', \n",
    "                 parse_dates=[\"date\"], date_parser=lambda x: pd.to_datetime(x, format=\"%Y-%m-%d %H:%M:%S\"))         \n",
    "        \n",
    "print('reservations: ')\n",
    "display(df.tail(1))\n",
    "\n",
    "# read the holiday data, include a date range column\n",
    "df_schulferien = pd.read_csv('data_preprocessed/Schulferien.csv', dtype={\"canton\": \"string\", \"population\": \"int32\"})\n",
    "df_schulferien['start'] = pd.to_datetime(df_schulferien['holidays_start'])\n",
    "df_schulferien['end'] = pd.to_datetime(df_schulferien['holidays_end'])\n",
    "df_schulferien = df_schulferien.drop(columns=[\"holidays_start\", \"holidays_end\"])\n",
    "\n",
    "print('schulferien: ')\n",
    "display(df_schulferien.tail(1))\n",
    "\n",
    "# train station coordinates data\n",
    "df_coordinates = pd.read_csv('data_preprocessed/dienststellen.csv')\n",
    "df_coordinates = df_coordinates[[\"abk_bahnhof\", \"lat\", \"lon\"]]\n",
    "df_coordinates = df_coordinates[df_coordinates['abk_bahnhof'].notna()]\n",
    "display(df_coordinates.tail(1))\n",
    "\n",
    "# weather data\n",
    "df_weather = pd.read_csv(\"data_preprocessed/weather.csv\")\n",
    "display(df_weather.tail(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11cfab56463119e89386f321ae32a8f4ddba59d2"
   },
   "source": [
    "#### 2) Wochentag <a name=\"stat\"></a>\n",
    "\n",
    "- Add a feature for weekday: 'weekday' and 'month'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "ea0865fdc8a2076e90f2f817c6af255cc3090630"
   },
   "outputs": [],
   "source": [
    "df['weekday'] = df['date'].dt.dayofweek\n",
    "df['month'] = df['date'].dt.month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Ferien <a name=\"stat\"></a>\n",
    "- Add a feature for number of people in holiday canton: n_holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each date, get the number of people in Switzerland who \n",
    "# are either on school holiday or national holiday..\n",
    "def get_holiday_people(date):\n",
    "    print(date)\n",
    "    filtered_holidays = df_schulferien[(df_schulferien['start']<=date)&(df_schulferien['end']>=date)]\n",
    "    is_national_holiday = (filtered_holidays[\"canton\"]==\"national\").sum()\n",
    "    if is_national_holiday:\n",
    "        people = 7917100\n",
    "    elif not(filtered_holidays.empty):\n",
    "        filtered_holidays = filtered_holidays[filtered_holidays[\"canton\"]!=\"national\"]\n",
    "        people = sum(filtered_holidays[\"population\"])\n",
    "    else: people=0\n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df, only 2021 data\n",
    "df=df[df['date']>='2021-01-01']\n",
    "\n",
    "#df['holiday_people'] = df.apply(lambda row : get_holiday_people(row['date']), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fe4cf230d2c14cbbcef7e26ebbb249777cfa7cb3"
   },
   "source": [
    "#### 3) Coordinates <a name=\"hr\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>res_id</th>\n",
       "      <th>res_dt</th>\n",
       "      <th>date</th>\n",
       "      <th>train_nr</th>\n",
       "      <th>line</th>\n",
       "      <th>reserved</th>\n",
       "      <th>capacity</th>\n",
       "      <th>bp_from</th>\n",
       "      <th>bp_to</th>\n",
       "      <th>...</th>\n",
       "      <th>dep_soll</th>\n",
       "      <th>arr_ist</th>\n",
       "      <th>arr_soll</th>\n",
       "      <th>res_delta_ist</th>\n",
       "      <th>res_delta_soll</th>\n",
       "      <th>res_delta_valid</th>\n",
       "      <th>lat_from</th>\n",
       "      <th>lon_from</th>\n",
       "      <th>lat_to</th>\n",
       "      <th>lon_to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29/03/2019 00:00</td>\n",
       "      <td>2019-04-01</td>\n",
       "      <td>510</td>\n",
       "      <td>IC 5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZUE</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>01/04/2019 07:03</td>\n",
       "      <td>01/04/2019 08:33</td>\n",
       "      <td>01/04/2019 08:32</td>\n",
       "      <td>284667.0</td>\n",
       "      <td>284634</td>\n",
       "      <td>False</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>8.540212</td>\n",
       "      <td>46.996727</td>\n",
       "      <td>6.935702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>283</td>\n",
       "      <td>290</td>\n",
       "      <td>06/04/2019 00:00</td>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>1528</td>\n",
       "      <td>IC 5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZUE</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>06/04/2019 16:30</td>\n",
       "      <td>06/04/2019 18:02</td>\n",
       "      <td>06/04/2019 18:01</td>\n",
       "      <td>59422.0</td>\n",
       "      <td>59418</td>\n",
       "      <td>False</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>8.540212</td>\n",
       "      <td>46.996727</td>\n",
       "      <td>6.935702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>357</td>\n",
       "      <td>365</td>\n",
       "      <td>07/04/2019 00:00</td>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>1524</td>\n",
       "      <td>IC 5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZUE</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>07/04/2019 14:30</td>\n",
       "      <td>07/04/2019 16:00</td>\n",
       "      <td>07/04/2019 16:01</td>\n",
       "      <td>52216.0</td>\n",
       "      <td>52218</td>\n",
       "      <td>False</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>8.540212</td>\n",
       "      <td>46.996727</td>\n",
       "      <td>6.935702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>611</td>\n",
       "      <td>619</td>\n",
       "      <td>11/04/2019 00:00</td>\n",
       "      <td>2019-04-11</td>\n",
       "      <td>1530</td>\n",
       "      <td>IC 5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZUE</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>11/04/2019 17:30</td>\n",
       "      <td>11/04/2019 19:00</td>\n",
       "      <td>11/04/2019 19:01</td>\n",
       "      <td>63021.0</td>\n",
       "      <td>63018</td>\n",
       "      <td>False</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>8.540212</td>\n",
       "      <td>46.996727</td>\n",
       "      <td>6.935702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>731</td>\n",
       "      <td>739</td>\n",
       "      <td>13/04/2019 00:00</td>\n",
       "      <td>2019-04-13</td>\n",
       "      <td>534</td>\n",
       "      <td>IC 5</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ZUE</td>\n",
       "      <td>NE</td>\n",
       "      <td>...</td>\n",
       "      <td>13/04/2019 19:03</td>\n",
       "      <td>13/04/2019 20:31</td>\n",
       "      <td>13/04/2019 20:32</td>\n",
       "      <td>68741.0</td>\n",
       "      <td>68634</td>\n",
       "      <td>False</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>8.540212</td>\n",
       "      <td>46.996727</td>\n",
       "      <td>6.935702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226731</th>\n",
       "      <td>226144</td>\n",
       "      <td>245085</td>\n",
       "      <td>29/10/2021 14:34</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1073</td>\n",
       "      <td>IC 6/61</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>IO</td>\n",
       "      <td>...</td>\n",
       "      <td>29/10/2021 15:05</td>\n",
       "      <td>29/10/2021 15:30</td>\n",
       "      <td>29/10/2021 15:28</td>\n",
       "      <td>1880.0</td>\n",
       "      <td>1860</td>\n",
       "      <td>True</td>\n",
       "      <td>46.686396</td>\n",
       "      <td>7.680103</td>\n",
       "      <td>46.690500</td>\n",
       "      <td>7.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226732</th>\n",
       "      <td>226173</td>\n",
       "      <td>245116</td>\n",
       "      <td>29/10/2021 19:54</td>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>1083</td>\n",
       "      <td>IC 6/61</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>IO</td>\n",
       "      <td>...</td>\n",
       "      <td>29/10/2021 20:05</td>\n",
       "      <td>29/10/2021 20:26</td>\n",
       "      <td>29/10/2021 20:28</td>\n",
       "      <td>622.0</td>\n",
       "      <td>660</td>\n",
       "      <td>True</td>\n",
       "      <td>46.686396</td>\n",
       "      <td>7.680103</td>\n",
       "      <td>46.690500</td>\n",
       "      <td>7.869000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226733</th>\n",
       "      <td>181405</td>\n",
       "      <td>196032</td>\n",
       "      <td>19/08/2021 17:43</td>\n",
       "      <td>2021-08-20</td>\n",
       "      <td>807</td>\n",
       "      <td>IC 8</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>VI</td>\n",
       "      <td>FR</td>\n",
       "      <td>...</td>\n",
       "      <td>20/08/2021 05:55</td>\n",
       "      <td>20/08/2021 06:11</td>\n",
       "      <td>20/08/2021 06:11</td>\n",
       "      <td>43970.0</td>\n",
       "      <td>43968</td>\n",
       "      <td>True</td>\n",
       "      <td>46.294029</td>\n",
       "      <td>7.881465</td>\n",
       "      <td>46.588908</td>\n",
       "      <td>7.651418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226734</th>\n",
       "      <td>193313</td>\n",
       "      <td>208346</td>\n",
       "      <td>02/09/2021 19:20</td>\n",
       "      <td>2021-09-03</td>\n",
       "      <td>807</td>\n",
       "      <td>IC 8</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>VI</td>\n",
       "      <td>FR</td>\n",
       "      <td>...</td>\n",
       "      <td>03/09/2021 05:55</td>\n",
       "      <td>03/09/2021 06:10</td>\n",
       "      <td>03/09/2021 06:11</td>\n",
       "      <td>38104.0</td>\n",
       "      <td>38148</td>\n",
       "      <td>True</td>\n",
       "      <td>46.294029</td>\n",
       "      <td>7.881465</td>\n",
       "      <td>46.588908</td>\n",
       "      <td>7.651418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226735</th>\n",
       "      <td>215384</td>\n",
       "      <td>233062</td>\n",
       "      <td>07/10/2021 20:41</td>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>807</td>\n",
       "      <td>IC 8</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>VI</td>\n",
       "      <td>FR</td>\n",
       "      <td>...</td>\n",
       "      <td>08/10/2021 05:55</td>\n",
       "      <td>08/10/2021 06:10</td>\n",
       "      <td>08/10/2021 06:11</td>\n",
       "      <td>33235.0</td>\n",
       "      <td>33288</td>\n",
       "      <td>True</td>\n",
       "      <td>46.294029</td>\n",
       "      <td>7.881465</td>\n",
       "      <td>46.588908</td>\n",
       "      <td>7.651418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226736 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  res_id            res_dt       date  train_nr     line  \\\n",
       "0                0       0  29/03/2019 00:00 2019-04-01       510     IC 5   \n",
       "1              283     290  06/04/2019 00:00 2019-04-06      1528     IC 5   \n",
       "2              357     365  07/04/2019 00:00 2019-04-07      1524     IC 5   \n",
       "3              611     619  11/04/2019 00:00 2019-04-11      1530     IC 5   \n",
       "4              731     739  13/04/2019 00:00 2019-04-13       534     IC 5   \n",
       "...            ...     ...               ...        ...       ...      ...   \n",
       "226731      226144  245085  29/10/2021 14:34 2021-10-29      1073  IC 6/61   \n",
       "226732      226173  245116  29/10/2021 19:54 2021-10-29      1083  IC 6/61   \n",
       "226733      181405  196032  19/08/2021 17:43 2021-08-20       807     IC 8   \n",
       "226734      193313  208346  02/09/2021 19:20 2021-09-03       807     IC 8   \n",
       "226735      215384  233062  07/10/2021 20:41 2021-10-08       807     IC 8   \n",
       "\n",
       "        reserved  capacity bp_from bp_to  ...          dep_soll  \\\n",
       "0              1       NaN     ZUE    NE  ...  01/04/2019 07:03   \n",
       "1              1       NaN     ZUE    NE  ...  06/04/2019 16:30   \n",
       "2              1       NaN     ZUE    NE  ...  07/04/2019 14:30   \n",
       "3              1       NaN     ZUE    NE  ...  11/04/2019 17:30   \n",
       "4              1       NaN     ZUE    NE  ...  13/04/2019 19:03   \n",
       "...          ...       ...     ...   ...  ...               ...   \n",
       "226731         1      12.0      SP    IO  ...  29/10/2021 15:05   \n",
       "226732         1       9.0      SP    IO  ...  29/10/2021 20:05   \n",
       "226733         1      15.0      VI    FR  ...  20/08/2021 05:55   \n",
       "226734         1       9.0      VI    FR  ...  03/09/2021 05:55   \n",
       "226735         1      17.0      VI    FR  ...  08/10/2021 05:55   \n",
       "\n",
       "                 arr_ist          arr_soll res_delta_ist  res_delta_soll  \\\n",
       "0       01/04/2019 08:33  01/04/2019 08:32      284667.0          284634   \n",
       "1       06/04/2019 18:02  06/04/2019 18:01       59422.0           59418   \n",
       "2       07/04/2019 16:00  07/04/2019 16:01       52216.0           52218   \n",
       "3       11/04/2019 19:00  11/04/2019 19:01       63021.0           63018   \n",
       "4       13/04/2019 20:31  13/04/2019 20:32       68741.0           68634   \n",
       "...                  ...               ...           ...             ...   \n",
       "226731  29/10/2021 15:30  29/10/2021 15:28        1880.0            1860   \n",
       "226732  29/10/2021 20:26  29/10/2021 20:28         622.0             660   \n",
       "226733  20/08/2021 06:11  20/08/2021 06:11       43970.0           43968   \n",
       "226734  03/09/2021 06:10  03/09/2021 06:11       38104.0           38148   \n",
       "226735  08/10/2021 06:10  08/10/2021 06:11       33235.0           33288   \n",
       "\n",
       "        res_delta_valid   lat_from  lon_from     lat_to    lon_to  \n",
       "0                 False  47.378177  8.540212  46.996727  6.935702  \n",
       "1                 False  47.378177  8.540212  46.996727  6.935702  \n",
       "2                 False  47.378177  8.540212  46.996727  6.935702  \n",
       "3                 False  47.378177  8.540212  46.996727  6.935702  \n",
       "4                 False  47.378177  8.540212  46.996727  6.935702  \n",
       "...                 ...        ...       ...        ...       ...  \n",
       "226731             True  46.686396  7.680103  46.690500  7.869000  \n",
       "226732             True  46.686396  7.680103  46.690500  7.869000  \n",
       "226733             True  46.294029  7.881465  46.588908  7.651418  \n",
       "226734             True  46.294029  7.881465  46.588908  7.651418  \n",
       "226735             True  46.294029  7.881465  46.588908  7.651418  \n",
       "\n",
       "[226736 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full join for start train station \n",
    "df = pd.merge(df, df_coordinates, left_on='bp_from', right_on='abk_bahnhof')\n",
    "df = df.drop(columns=['abk_bahnhof']).rename(columns={\"lat\": \"lat_from\", \"lon\": \"lon_from\"})\n",
    "\n",
    "# full join for destination\n",
    "df = pd.merge(df, df_coordinates, left_on='bp_to', right_on='abk_bahnhof')\n",
    "df = df.drop(columns=['abk_bahnhof']).rename(columns={\"lat\": \"lat_to\", \"lon\": \"lon_to\"})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dd1ffa6086d61b5e0b8535647eb896656f247d8"
   },
   "outputs": [],
   "source": [
    "#Create month column (Run this only once)\n",
    "df_air['MONTH']=df_air.index.month     \n",
    "df_air.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77ebd67e6a32310fcc8f7943c538cd7c7f0ebd63"
   },
   "source": [
    "- ##### Drop column NMHC_GT; it has 90% missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f00bc5da96c4db8d2d23a704fa45321cfeaeb682"
   },
   "outputs": [],
   "source": [
    "df_air['CO_GT']=df_air['CO_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['CO_GT'].transform('mean'))\n",
    "df_air['NOX_GT']=df_air['NOX_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['NOX_GT'].transform('mean'))\n",
    "df_air['NO2_GT']=df_air['NO2_GT'].fillna(df_air.groupby(['MONTH','HOUR'])['NO2_GT'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print left missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0b5243ab00b71b52fa0a102e317a6d9c64d9f97"
   },
   "outputs": [],
   "source": [
    "print('Left out missing value:')\n",
    "df_air.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07f1ae983958da0bf9af2294836a865c8bb69f5c"
   },
   "outputs": [],
   "source": [
    "# Fill left out NaN values with hourly average value\n",
    "df_air['CO_GT'] = df_air['CO_GT'].fillna(df_air.groupby(['HOUR'])['CO_GT'].transform('mean'))\n",
    "df_air['NOX_GT'] = df_air['NOX_GT'].fillna(df_air.groupby(['HOUR'])['NOX_GT'].transform('mean'))\n",
    "df_air['NO2_GT'] = df_air['NO2_GT'].fillna(df_air.groupby(['HOUR'])['NO2_GT'].transform('mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a390f0e9e8b4950475913663213bcd833f8cbeb6"
   },
   "source": [
    "#### 4) Understand correlation between variables<a name=\"corr\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Use heatmap to see correlation between variables\n",
    " - Describe the heatmap using your own words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f66b54be3ee221420ba23c9f218451680ac2f41",
    "hideCode": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.heatmap(df_air.corr(), annot=True,fmt='.1f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - PT08_S3_NOX negatively correlated to other air pollutants\n",
    " - All the other pollutants strongly correlated\n",
    " - weather variables (T, RH, AH) have relatively weak correlation with air quality parameters\n",
    " - temperature strongly correlated with absolute- and relative humidity \n",
    " - target variable RH: highest linear correlation to temperature and hour of the day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0fe8d6fcdfaaa654c94beedbb693a04ddadf536e"
   },
   "source": [
    "#### 5) Try to understand degree of linearity between RH output and other input features<a name=\"lin\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - plot all X-features against output variable RH using `sns.lmplot`\n",
    " - describe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d6bdaf849efada7176e4fd3d13ca7eb5f1fa484",
    "hideCode": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot all X-features against output variable RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove date and time columns \n",
    "df_air =df_air.drop(['DATE', 'TIME'], axis=1)\n",
    "\n",
    "# melt dataframe and plot all variables against X-features\n",
    "df_air_melt = pd.melt(df_air, 'RH', var_name='cols', value_name='vals')\n",
    "g = sns.lmplot(x='vals', y='RH', col='cols', col_wrap=5, data=df_air_melt, sharex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Most features don't seem to correlate with the target variable (the plots are just point clouds).\n",
    "- Temperature has a somewhat linear relationship with RH, but the residuals are not normally distributed around the linear regression line (for high temperatures, RH is always overestimated by the regressor).\n",
    "- Hour and month are clearly related to RH, but the relationship is clearly not linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdea423dd5a6909235b58e471b4400c6b13cce25"
   },
   "source": [
    "### 6) Linear Regression<a name=\"LR\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18a2075d29238b5d89d6676b731bf7ced805c2ec"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler         #import normalisation package\n",
    "from sklearn.model_selection import train_test_split      #import train test split\n",
    "from sklearn.linear_model import LinearRegression         #import linear regression package\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error   #import mean squared error and mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8cfe7db69f4cbaa5c07e56de9aae8eb79f7fb5f"
   },
   "source": [
    "- ##### Define Feature (X) and Target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37cb056fb7da95fa970bf47375b9fae7d2324bb2"
   },
   "outputs": [],
   "source": [
    "X = df_air.drop('RH', axis=1).values #X-input features\n",
    "y = df_air.RH.values #y-input features           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot distribution of target variable. Do we need to use stratified splitting of the data? Why?\n",
    "\n",
    "I would argue that we don't need stratified splitting in this case, because the distribution of RH is symmetric. I would use stratified splitting in the case of a skewed distribution or in a classification problem, if there are few data points of a certain class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y, bins=50)\n",
    "plt.title('Distribution of RH values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44530f9871590d84d917d8823110e38ff24fb56b"
   },
   "source": [
    "- ##### Train test split\n",
    "split the data into train and test with test size and 30% and train size as 70%, use a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5c807208b968db8fd484a7fb94cc01bc85ba9278"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# for stratified splitting: used code from this website\n",
    "# https://michaeljsanders.com/2017/03/24/stratify-continuous-variable.html\n",
    "# bins=np.linspace(0, 100, 10)\n",
    "# y_binned = np.digitize(y, bins)\n",
    "# stratify=y_binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6da09964d8a20171a1cf8fb0b4ecd2d25bf582ba"
   },
   "outputs": [],
   "source": [
    "print('Training data size:'), print(X_train.shape)\n",
    "print('Test data size:'), print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7231f2173db0d89b411e0f97766f690a8a2820ff"
   },
   "source": [
    "- ##### Normalize data using `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e962d38ebed67ad1c22620367a0d86dc6bde59bc"
   },
   "outputs": [],
   "source": [
    "# fit standard scaler on training data\n",
    "scaler=StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15952593f56d59f728e9ad930267b25ff8a573cc"
   },
   "outputs": [],
   "source": [
    "# transform training and test data\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "45bb5e52af895a267c874a8dd18ac6cd6ad98f22"
   },
   "source": [
    " - ##### Train the Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "159571147e44944d8b92f804e1e3a8a6fda0784e"
   },
   "outputs": [],
   "source": [
    "LinearModel=LinearRegression().fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Print intercept and slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc5bf141431b1bc0e87c6ec4355ed13d74ad733b"
   },
   "outputs": [],
   "source": [
    "print('Intercept: ', LinearModel.intercept_)\n",
    "print('Slope: ', LinearModel.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Predict on the test data\n",
    "- Compute and print performance metrics as RMSE. This will be our baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9eb76c8a7d964fcc3e0975de450921802d8468e4"
   },
   "outputs": [],
   "source": [
    "y_pred = LinearModel.predict(X_test_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print('RMSE baseline', \"%.3f\" % rmse)\n",
    "\n",
    "# plot distribution of predicted RH values\n",
    "# plt.hist(y_pred, bins=50)\n",
    "# plt.title('Distribution of predicted RH values')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0b12a8d38da8d0994b1169be384e3992e3c1280"
   },
   "source": [
    "#### <u>6a) Conclusion of baseline linear regression model:<a name=\"LRcon\"></a>\n",
    "    \n",
    "Write your conclusions here: \n",
    "    \n",
    "A linear regressor is not the best choice for the given task. The lmplots show that the linear relationships of most features with the target variable are weak. Moreover the linear regressor predicts some negative values for RH, which does not make sense physically. A reasonable model should account for this restriction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b97f6943c00521d768fd9e225dcaa6d4ed5ad29"
   },
   "source": [
    "### 7) Feature engineering and testing model:<a name=\"FE\"></a>\n",
    "\n",
    "Try with multiple feature combination and see if RMSE is improving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fc53443f0abbb1bb8f932b4e76939088a62b0c7a"
   },
   "source": [
    "- ##### write function to measure RMSE with different combinations of features (try at least 6 combinations of your choice)\n",
    "\n",
    "(remember to comment the function!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b917e0c10ce602ff97e72786b1f9fa9a05a99e63"
   },
   "outputs": [],
   "source": [
    "def train_test_RMSE(df_air, feat_):\n",
    "    \n",
    "    '''\n",
    "    The function train_test_RMSE returns the RMSE for different combinations \n",
    "    of features feat_ of the dataframe df_air'''\n",
    "    \n",
    "    # select feature and target variables \n",
    "    X = df_air[feat_].values #X-input features\n",
    "    y = df_air.RH.values #y-input features  \n",
    "    \n",
    "    # split train and test data\n",
    "    np.random.seed(21)\n",
    "    \n",
    "    X_trainR, X_testR, y_trainR, y_testR = train_test_split(X, y, test_size=0.3, random_state=21)\n",
    "    \n",
    "    # scale features\n",
    "    scaler=StandardScaler().fit(X_trainR)\n",
    "    X_trainR_scaled=scaler.transform(X_trainR)\n",
    "    X_testR_scaled=scaler.transform(X_testR)\n",
    "    \n",
    "    # apply linear regression model\n",
    "    LinearModel=LinearRegression().fit(X_trainR_scaled, y_trainR)\n",
    "    y_predR=LinearModel.predict(X_testR_scaled)\n",
    "    \n",
    "    # return rmse value\n",
    "    return np.sqrt(mean_squared_error(y_testR, y_predR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1b4f81132b6dc1a86095dc0ef363ef71c9aeeb8"
   },
   "outputs": [],
   "source": [
    "feat_1=['T']\n",
    "feat_2=['T', 'AH']\n",
    "feat_3=['T', 'AH', 'HOUR']\n",
    "feat_4=['AH', 'T', 'MONTH', 'HOUR']\n",
    "feat_5=list(df_air.drop(['RH', 'T', 'MONTH', 'HOUR'], axis=1).columns.tolist())\n",
    "feat_6=list(df_air.drop(['RH', 'T'], axis=1).columns.tolist())\n",
    "feature_combinations = [feat_1, feat_2, feat_3, feat_4, feat_5, feat_6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3fcd6877c683d5335f94e6fa44190f33bdec2fb"
   },
   "outputs": [],
   "source": [
    "rmse_dict = {}\n",
    "for feat_comb in feature_combinations:\n",
    "    rmse_combination = train_test_RMSE(df_air, feat_comb)\n",
    "    rmse_dict[rmse_combination] = feat_comb\n",
    "    print('Feature combination: ', feat_comb)\n",
    "    print('RMSE: ', \"%.3f\" % rmse_combination, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d434585b7284b2e87a49a69eb7394ff7b0fe23c"
   },
   "source": [
    "#### <u>7a) Conclusion of Feature Engineering and testing:<a name=\"FEcon\"></a>\n",
    "    \n",
    "    - Write your conclusions here\n",
    "    \n",
    "    1) Using only a subset of features decreases the accuracy of the model. However, a combination of few features such as combination 2 (AH, T) results in a model that is almost as accurate with much reduced number of parameters. These two features are the most important ones to include in the model, which makes sense due to the direct physical relationship between T, RH and AH. \n",
    "    2) Using all features except for temperature (combination 6) results in a much worse model.\n",
    "    3) Using temperature alone results in a much worse model than when combining it with AH.\n",
    "    4) Using the temporal features (hour, month) does not result in a good model. Even though the two variables are related to the target variable, the non-linear relationship is not captured well by the Linear Regressor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c9b4dd7c82bf372612fdb301c7ed59dbf93781d7"
   },
   "source": [
    "### 8) Decision Tree Regression<a name=\"DT\"></a>\n",
    "\n",
    "Let us try to apply Decision tree regression technique and see if any improvement happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ece8c66fa537470bc165472221ea3eb7fc371ac"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor         #Decision tree regression model\n",
    "from sklearn.model_selection import cross_val_score    #import cross validation score package\n",
    "from sklearn.model_selection import GridSearchCV        #import grid search cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cd00140f7405c5d213fd37af8776867b40b98ee"
   },
   "source": [
    "- ##### Fit the DT model and predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e521980e8e0c531358cbd0871709268feb382df1"
   },
   "outputs": [],
   "source": [
    "DecisionTree=DecisionTreeRegressor().fit(X_train_scaled, y_train)\n",
    "y_pred = DecisionTree.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48f647b2e5e46d5bad3988bf0475ef0bc7237013"
   },
   "source": [
    "- ##### RMSE of RH prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8746927d99271c2ddda379c45a4aef3035e997ab"
   },
   "outputs": [],
   "source": [
    "#calculate RMSE\n",
    "print('RMSE of Decision Tree Regression:', \"%.3f\" % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eaa340d761a6f2eeddb8982912f2e1f304019562"
   },
   "source": [
    "#### <u>Conclusion:<u>(Decision Tree Regression)\n",
    "\n",
    "    - Write your conclusions here\n",
    "    The decision tree works much better than the linear regression because it can account for non-linear relationships between the features and target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4904dbd6ee5dfcddc63d1d580c15586195b9b5c9"
   },
   "source": [
    "### 9) Random Forest Regression<a name=\"RF\"></a>\n",
    "\n",
    "- apply Random Forest regression and measure RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15cdc478bbd1d46d4e576e84e878df5be1b850c9"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor           #import random forest regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a943435d37f60e8281ca0360283b37cb0669813"
   },
   "source": [
    "- ##### Fit the RF model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64b4eb02c2bca90f571a5782499f48de0245b965"
   },
   "outputs": [],
   "source": [
    "RF=RandomForestRegressor().fit(X_train_scaled, y_train)\n",
    "y_pred = RF.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bfcd4f1a0ff4136bcecfe113a890d517ef198183"
   },
   "source": [
    "- ##### RMSE of RH prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7d2c6f2b866fdc699dd10608a094132e7b2621b6"
   },
   "outputs": [],
   "source": [
    "#Calculate RMSE\n",
    "print('RMSE of predicted RH in RF model:', \"%.3f\" % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "be1732d23226a6134376336680d3fc18514324d1"
   },
   "source": [
    "- ##### Try to improve on baseline RF model: use `GridSearchCV` to search between different hyperparameters and plot the resulting RMSE\n",
    "    - use different numbers of estimators\n",
    "    - use cv of 5 or 10\n",
    "    - use the correct scoring function\n",
    "    - then, use the best model hyperparameters to predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36b4737670e2c8e3a4363b19e01c4e92eb9bab0d"
   },
   "outputs": [],
   "source": [
    "# i used the example here as a reference\n",
    "# https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 10, 100]\n",
    "\n",
    "# Create the random grid, for now only look for the best number of trees \n",
    "grid = {'n_estimators': n_estimators}\n",
    "               #'max_features': max_features,\n",
    "               #'max_depth': max_depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = RF, param_grid = grid, cv=5)\n",
    "\n",
    "# Fit the model with different parameters from the grid to the data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "#print best parameters\n",
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a56923a2a9049104c7f82a588c03296d369b2404"
   },
   "outputs": [],
   "source": [
    "print('RMSE using RF grid search method', \"%.3f\" % np.sqrt(mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write here your conclusions regarding the Grid Search method. Did the performance improve? How much?\n",
    "\n",
    "The default number of trees in the RF model is 100. From GridSearch CV we find that increasing the number of trees to 200 or 400 improves the performance. The RMSE of the predicted target variable decreases by around 1-2% compared to the default RF model. Depending on the application this can be a significant improvement of performance but the additional computation effort may be also considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Plot box plots of the error <a name=\"bxplot\"></a>\n",
    "\n",
    "    - how are the error distributed over different ranges of RH?\n",
    "    - plot the box plots of absolute errors vs different output range) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = pd.DataFrame(data={'RH': y_test, 'RH_predicted': y_pred, 'abs_error': np.abs(y_pred - y_test)})\n",
    "df_error['RH_bins']=pd.cut(df_error['RH'], np.arange(0, 110, 10))\n",
    "sns.boxplot(x=df_error.RH_bins, y=df_error.abs_error)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest errors occur at the edge of the distribution.\n",
    "This could be caused by the distribution of the target variable (less training samples at the edges) and could possibly be improved by using stratified splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b5f0b96cc0e6a21fbf588ecb622795f91d57deb9"
   },
   "source": [
    "#### <u>Conclusion: Random Forest\n",
    "    \n",
    "    - Write your conclusions here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random Forest algorithm further increases the accuracy. It is less prone to overfitting compared to the decision tree model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ce39a28c254a8e5c8e8db100563e501e10aa9559"
   },
   "source": [
    "### 10) Support Vector Machine<a name=\"SVM\"></a>\n",
    "\n",
    "- apply SVR and measure RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b24920e6ee1a7682ba3465c08be7d52f5c073693"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR           #import support vector regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e6c218855ebd20d406fdfc66e51433da0ad523d0"
   },
   "outputs": [],
   "source": [
    "SVM=SVR(kernel='rbf').fit(X_train_scaled, y_train)\n",
    "y_pred = SVM.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7a0dbe11cf0d0dc153cb0e83f6659652aa2df1d"
   },
   "outputs": [],
   "source": [
    "#Calculate RMSE of SVR\n",
    "print('RMSE of SVR model:', \"%.3f\" % np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7c7f98858b5f4bdaf0a53139127847fbe90a614"
   },
   "source": [
    "## Conclusion:<a name=\"conclusion\"></a>\n",
    "\n",
    " - Summarize here your conclusions regarding the models used \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment I learned to apply different regression models.\n",
    "However, to solve the task in reality, I think it would make sense to consider the time series structure of the data. The simple linear regressor cannot learn much from the features 'month' and 'hour' even though they are clearly related to the target variable (in a non-linear way). The other regressors such as the decision tree and RF account for the non-linearity and therefore provide more accurate predictions of the target variable.\n",
    "\n",
    "Considering the physical relationships between temperature, AH and RH could also improve the model, e.g. compute an additional feature for the saturation vapor pressure (function of temperature)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}